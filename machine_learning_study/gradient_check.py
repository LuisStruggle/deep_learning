import numpy as np
from random import randrange


def eval_numerical_gradient(f, x):
    """
    比较暴力的方式求解数值梯度
    - f 是一个要求梯度的函数
    - x 是函数f的输入x
    """

    fx = f(x)  # evaluate function value at original point
    grad = np.zeros(x.shape)
    h = 0.00001

    # iterate over all indexes in x
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:

        # evaluate function at x+h
        ix = it.multi_index
        x[ix] += h  # increment by h
        fxh = f(x)  # evalute f(x + h)
        x[ix] -= h  # restore to previous value (very important!)

        # compute the partial derivative
        grad[ix] = (fxh - fx) / h  # the slope
        print(ix, grad[ix])
        it.iternext()  # step to next dimension

    return grad


def grad_check_sparse(f, x, analytic_grad, num_checks):
    """
        取一些维度，比对上面的数值梯度和解析梯度.
    """
    h = 1e-5

    for i in range(num_checks):
        ix = tuple([randrange(m) for m in x.shape])

        x[ix] += h  # increment by h
        fxph = f(x)  # evaluate f(x + h)
        x[ix] -= 2 * h  # increment by h
        fxmh = f(x)  # evaluate f(x - h)
        x[ix] += h  # reset

        grad_numerical = (fxph - fxmh) / (2 * h)
        grad_analytic = analytic_grad[ix]
        rel_error = abs(grad_numerical - grad_analytic) / (
            abs(grad_numerical) + abs(grad_analytic))
        print('numerical: %f analytic: %f, relative error: %.3f' %
              (grad_numerical, grad_analytic, rel_error))
